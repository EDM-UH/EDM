{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 6.5 - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "def convert_class(in_string):\n",
    "    if in_string == 'First':\n",
    "        return 1\n",
    "    elif in_string == 'Second':\n",
    "        return 2\n",
    "    elif in_string == 'Third':\n",
    "        return 3\n",
    "\n",
    "titanic['class'] = titanic['class'].apply(convert_class)\n",
    "titanic['sex'] = titanic['sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "\n",
    "embarked_onehot = pd.get_dummies(titanic.embarked, drop_first=True)\n",
    "class_onehot = pd.get_dummies(titanic.embark_town, drop_first=True)\n",
    "deck_onehot = pd.get_dummies(titanic.deck, drop_first=True)\n",
    "deck_onehot = pd.get_dummies(titanic.who, drop_first=True)\n",
    "\n",
    "titanic = pd.concat([titanic, embarked_onehot, class_onehot, deck_onehot], axis = 'columns')\n",
    "titanic = titanic.drop(['embarked','embark_town','deck','who'], axis = 'columns')\n",
    "titanic = titanic.drop('alive', axis = 'columns')\n",
    "titanic.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = titanic.drop('survived', axis = 'columns')\n",
    "y = titanic.survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(strategy='mean')\n",
    "imp.fit(X_train)\n",
    "X_train = imp.transform(X_train)\n",
    "X_test = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# How do we decide which hyperparameters to use?\n",
    "With the random forest from earlier, we just played around with different values. One method to find the right values is to perform an exhaustive search over all combinations of values. This is a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import grid search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# define a dictionary of value ranges. the dictionary keys are some random forest parameters\n",
    "\n",
    "\n",
    "# initialize a grid search object with an estimator, parameter grid, scoring option, and number of cv-folds\n",
    "\n",
    "\n",
    "# fit the grid search object to training data. it will search the grid for the best parameter values given\n",
    "# ...the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# After a grid search object has been fit, it can return the estimator with the best parameters\n",
    "\n",
    "\n",
    "# It can return just the best parameters\n",
    "\n",
    "\n",
    "# It can return the best cross-validated score\n",
    "\n",
    "\n",
    "# It can return scores for every parameter combination. here we just display the first 10 combinations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Your turn. Perform a grid search for the best logistic regression parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import LogisticRegression\n",
    "\n",
    "\n",
    "# initialize estimator object\n",
    "\n",
    "\n",
    "# define dictionary of parameter ranges\n",
    "\n",
    "\n",
    "# initialize grid search object\n",
    "\n",
    "\n",
    "# fit the grid to perform a grid search\n",
    "\n",
    "\n",
    "# print the best parameters\n",
    "\n",
    "\n",
    "# print best score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Pipelining then grid searching\n",
    "You can even grid search on a pipeline object!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's bring back our imperfect titanic dataset. We want to perform missing value imputation, feature scaling, and prediction using an svm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = titanic.drop('survived', axis = 'columns')\n",
    "y = titanic.survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import Pipeline, SVC, and transformer classes\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "\n",
    "# initialize objects we want to put in the pipeline\n",
    "\n",
    "\n",
    "# define the steps we want our pipeline to take. here we add transformers and an optional estimator at the end.\n",
    "# these must always take the form of a list of tuples.\n",
    "# the names you give in the first position of each tuple is used when defining the dictionary of parameters.\n",
    "\n",
    "\n",
    "# initialize pipeline with dictionary of steps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### When defining the dictionary of parameters, we must now specify the transformer/object the paramater belongs to in the dictionary keys. This is done with *two underscores*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# remember that we're performing a grid search over parameters for multiple objects in a pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### If you use the grid search object to predict, it will use the best estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
